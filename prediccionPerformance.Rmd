---
title: 'Clasificación'
author: 'Barrera Borla, Gonzalo y Duarte, Octavio M.'
date: '27 de Noviembre'
output:
  html_document
---

```{r librerias}
library('tidyverse')
```

# Carga de los Datos

```{r datos}
read_table(
  "Concurso_Estima.txt",
  col_names = c( 'ciclo', 'minMem', 'maxMem', 'cache', 'minCanales', 'maxCanales', 'perfoRelativa' ),
  ) -> datos
```

# Exploración

Parece natural introducir una transformada del tiempo de ciclo de procesador que sea la inversa, "frecuencia". Sobre todo porque la relación de "más es mejor" es más intruitiva.

## Gráfico de Facetas

```{r exploración}
datos <- mutate( datos, frecuencia = 1/ciclo )

datos %>% gather( 'frecuencia', 'ciclo', 'minMem', 'maxMem', 'cache', 'minCanales', 'maxCanales', key = explicadora, value = valor  ) %>% ggplot() +
            aes( y = perfoRelativa, x = valor, color = explicadora ) +
            geom_point() +
  facet_wrap( .~explicadora, scales = "free_x" )
```

## Correlaciones

```{r correlaciones}
correlaciones <- cor( datos )
correlaciones
```

* La mejor correlación con la variable en estudio la presentan las variables asociadas a la memoria `minMem` con `r correlaciones['minMem','perfoRelativa']` y `maxMem` `r correlaciones['maxMem','perfoRelativa']`.
* La correlación entre ellas mismas es alta `r correlaciones['minMem','maxMem']`.
* Excepto `ciclo` todas las demás tienen una correlación suficiente como para suponer que se puede extraer información útil al modelo de ellas. La transformada de `ciclo`, `frecuencia` sí muestra una correlación razonable.


# Intento de Transformar para lograr Linealidad y Homoscedasticidad.

## Transformando la Repuesta

```{r minMem transformada}
datos <- mutate( datos, logPerfo = log(perfoRelativa), raizPerfo = sqrt(perfoRelativa) )

datos %>% gather( 'logPerfo', 'raizPerfo' , key = respuesta, value = valor  ) %>%  ggplot() +
  aes( x = minMem, y = valor, color = respuesta ) +
  geom_point() +
  facet_grid( .~respuesta )
```

Ambas transformaciones parecen haber reducido drásticamente la heteroscedasticidad. No pude poner la original en el gráfico porque no logro que `facet_grid` responda al comando `scales = "free"` y como tiene una escala enorme no dejaba visualizar las transformadas. 


## Intento de Optimizar la Transformación Potencial (es decir, la mejor raíz) sobre `perfoRelativa`.

### Elegir una función objetivo

No es fácil elegir una función objetivo. 

Opciones posibles:
*Estadístico de algún test (por ejemplo Breusch y pagan).
*El r cuadrado ajustado de una regresión, en principio un ajuste lineal.
*Una medida ad-hoc del tipo "diferencia entre la varianza en el 2 y en el 4 quintiles" ordenadas según `perfoRelativa`. Quizás es mejor tomar el segundo y noveno deciles, que se asocian a la poda al 20% (aunque esta es sobre el residuo).

```{r herramientas para optimización}
# Esta función necesita una función medida que es por ejemplo la llamada a un modelo lineal. Lo ideal es currificarla con este parámetro para mayor comodidad.

unPasoBiparticion <- function(inf, medidaI, sup, medidaS, funcionMedida, optimoBuscado = c( "max","min" )) {
  candidato <- 0.5*(sup + inf)
  medidaC <- funcionMedida(candidato)
  tabla <- tibble(
    lambda = c(inf,sup,candidato),
    medida = c(medidaI,medidaS,medidaC)
  )
  indiceMenorMedida <- which( tabla$medida == reduce(tabla$medida,min) )
  indiceMayorMedida <- which( tabla$medida == reduce(tabla$medida,max) )
  indiceARetirar <- ifelse( optimoBuscado == 'max', indiceMenorMedida, indiceMayorMedida )
  tabla <- tabla[-indiceARetirar,]
  indiceInf <- which( tabla$medida == reduce(tabla$medida,min) )
  indiceSup <- which( tabla$medida == reduce(tabla$medida,max) )
  return(
    list(
      "inf" = (tabla$lambda)[indiceInf],
      "medidaI" = (tabla$medida)[indiceInf],
      "sup" = (tabla$lambda)[indiceSup],
      "medidaS" = (tabla$medida)[indiceSup]
    )
  )
}

#esta función necesita como argumento una función de paso de la bipartición deseada que toma cuatro argumentos, es la versión curryficada de unPasoBiparticion. Lo ideal es curryficar también.

iterarBiparticion <- function(n, inf0, sup0, funcionPasoBiparticion, funcionMedida) {
  inf <- inf0
  medidaI <- funcionMedida(inf)
  sup <- sup0
  medidaS <- funcionMedida(sup)
  while ( n > 0 ) {
    arg <- funcionPasoBiparticion(inf, medidaI, sup, medidaS)
    n <- n-1
    inf <- arg$inf
    medidaI <- arg$medidaI
    sup <- arg$sup
    medidaS <- arg$medidaS
  }
  return(
    list(
      "lambda" = sup,
      "medida" = medidaS
    )
  )
}
```

```{r optimizacion en el exponente}
explicadoras <- c('frecuencia', 'minMem', 'maxMem', 'cache', 'minCanales', 'maxCanales')

# Definimos la función objetivo que sólo toma el parámetro a optimizar y tiene fijos la tabla, modelo, etc. 

varianzaObjetivo <- function(lambda) {
  modeloLineal <- lm( perfoRelativa^lambda ~ frecuencia + minMem+ maxMem+ cache+ minCanales+ maxCanales, datos )
  varianza <- ( summary( modeloLineal ) )$sigma
  return(varianza)
}

# definimos un paso de la optimización, que fija la función de medida u objetivo y el tipo de extremo. 

pasoOptimizarVarianza <- function(inf, medidaI, sup, medidaS)
{
  unPasoBiparticion(inf, medidaI, sup, medidaS,
                    varianzaObjetivo,
                    optimoBuscado = "min"
)
}

# usamos la función de iterar para lograr la deseada en este caso. 

optimizarVarianza <- function(n, inf0, sup0)  {
  iterarBiparticion(n, inf0, sup0, pasoOptimizarVarianza, varianzaObjetivo)
}

```


## Transformando una Explicadora

```{r perfo transformada}
datos <- mutate( datos, logMinMem = log(minMem), raizMinMem = sqrt(minMem) )

datos %>% gather( 'minMem', 'logMinMem', 'raizMinMem' , key = explicadora, value = valor  ) %>% dplyr::select( one_of('perfoRelativa','explicadora','valor') ) %>% ggplot() +
  aes( y = perfoRelativa, x = valor, color = explicadora ) +
  geom_point() +
  facet_grid( .~explicadora, scales = "free" )
```


Los dos problemas son la acumulación de los datos en los primeros valores de la variable y la heteroscedasticidad. 

## Primer Intento para Reducir la Heteroscedasticidad


# Ideas no Descabelladas

* Él dio en clase un truco econométrico que es usar los residuos de un modelo lineal como estimadores de los pesos para hacer cuadrados pesados ordinarios pesados. Es decir, estos residuos pueden ser la matriz de covarianzas. Tengo que releer lo que anotó. 
* Regresión no paramétrica por núcleos (la de los kernel de análisis exploratorio).

# Ideas Descabelladas

## Usar la ley de Moore para obtenter una variable análoga a "Tiempo".

En aquellos tiempos la relación se cumplía muy bien (creo que era duplicación de la perforance cada dos años). Quizás se puede transformar la performance relativa en una serie de tiempo y usar algún método para series de tiempo autoregresivas. 
Lo bueno de algo así es que se come la heteroscedasticidad. 

Lo malo es que es un delirio. 
