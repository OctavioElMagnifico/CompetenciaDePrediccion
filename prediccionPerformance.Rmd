---
title: 'Clasificación'
author: 'Barrera Borla, Gonzalo y Duarte, Octavio M.'
date: '27 de Noviembre'
output:
  html_document
---

```{r librerias}
library('tidyverse')
library('randomForest')
library('caret')
```

### Epílogo

*Ignorante que blasonas de sabio: angustiado te veo entre el infinito del pasado y el infinito del porvenir. Quisieras poner límite entre estos dos infinitos y detenerte... Siéntate antes bajo un árbol con un cántaro de vino y olvidarás tu impotencia.* 

Omar Jayam, Rubaiyat. 

# Carga de los Datos

```{r datos}
read_table(
  "Concurso_Estima.txt",
  col_names = c( 'ciclo', 'minmem', 'maxmem', 'cache', 'mincan', 'maxcan', 'perfo' ),
  ) -> datos
```

# Exploración

Parece natural introducir una transformada del tiempo de ciclo de procesador que sea la inversa, "freq". Sobre todo porque la relación de "más es mejor" es más intruitiva.
 Como está medida en nanosegundos, multiplicamos por mil millones para llegar a segundos, pero como ues una medida incómoda tomamos una constante menor. 

## Gráfico de Facetas

```{r exploración}
datos <- mutate( datos, freq = 10^2 * 1/ciclo )

datos %>% gather( 'freq', 'ciclo', 'minmem', 'maxmem', 'cache', 'mincan', 'maxcan', key = explicadora, value = valor  ) %>% ggplot() +
            aes( y = perfo, x = valor, color = explicadora ) +
            geom_point() +
  facet_wrap( .~explicadora, scales = "free_x" )
```

## Correlaciones

```{r correlaciones}
correlaciones <- cor( datos )
correlaciones
```

* La mejor correlación con la variable en estudio la presentan las variables asociadas a la memoria `minmem` con `r correlaciones['minmem','perfo']` y `maxmem` `r correlaciones['maxmem','perfo']`.
* La correlación entre ellas mismas es alta `r correlaciones['minmem','maxmem']`.
* Excepto `ciclo` todas las demás tienen una correlación suficiente como para suponer que se puede extraer información útil al modelo de ellas. La transformada de `ciclo`, `freq` sí muestra una correlación razonable.


# Intento de Transformar para lograr Linealidad y Homoscedasticidad.

## Transformando la Repuesta

```{r minmem transformada}
datos <- mutate( datos, logPerfo = log(perfo), raizPerfo = sqrt(perfo) )

datos %>% gather( 'logPerfo', 'raizPerfo' , key = respuesta, value = valor  ) %>%  ggplot() +
  aes( x = minmem, y = valor, color = respuesta ) +
  geom_point() +
  facet_grid( .~respuesta )
```

Ambas transformaciones parecen haber reducido drásticamente la heteroscedasticidad. No pude poner la original en el gráfico porque no logro que `facet_grid` responda al comando `scales = "free"` y como tiene una escala enorme no dejaba visualizar las transformadas. 

# Elección de un Método

Armados de estas nociones para orientarnos, recurrimos a iterar una lista muy grande de modelos sobre los métodos que conocemos. 
Un paquete que homogeneiza esta tarea para una gran cantidad de algoritmos es `caret`. Este separa la tarea de realizar una predicción en varias etapas, todas modulares y por lo tanto fue posible porgramar la métrica particular que estamos usando en esta trabajo, *alfa podada* al 80%. 
Además, se definió esta medición de tal forma que acepta una función inversa. De esta manera, pudimos realizar regresiones sobre modelos donde la variable está transformada (dado que las observaciones preliminares parecieron revelar la ventaja de estas transformaciones) pero medir el *Error Medio Cuadrático Alfa Podado* sobre nuestra variable respuesta original. 
Una primera observación es que esta poda homogeneiza drásticamente el rendimiento de los modelos y por lo tanto fue una batalla cabeza a cabeza, al menos entre los modelos que nosotros conocemos. 

# Modelo Seleccionado

El modelo seleccionado fue "Bosques Aleatorios" en su adaptación para regresiones, implementado por la librería `randomForest`, la más clásica de las disponibles, con código de los desarrolladores originales del algoritmo.

```{r bosque}
datos$obs <- seq(1:nrow(datos))
atipicos1 <- c(123,27)
datos2 <- datos[-atipicos1,]
bosqueLog <- randomForest( log(perfo) ~ (freq + mincan + maxcan + minmem + maxmem + cache)^2, datos2, mtry = 2 )

datos2$ajustados <- bosqueLog$predicted %>% exp()

datos2 <- mutate( datos2, residuos = perfo - ajustados )

datos2 %>% ggplot() +
  aes( x = perfo , y = ajustados, label = obs ) +
  geom_label()
```



